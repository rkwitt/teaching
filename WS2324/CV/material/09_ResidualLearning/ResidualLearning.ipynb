{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision (911.908)\n",
    "\n",
    "## <font color='crimson'>Residual Learning</font>\n",
    "\n",
    "**Changelog**:\n",
    "- *Sep. 2021*: initial version\n",
    "- *Jan. 2023*: PyTorch 1.13 adaptations and fixes\n",
    "\n",
    "---\n",
    "\n",
    "In this part of the lecture, we cover one of the current state-of-the-art neural network architectures for visual recognition, *ResNets*, introducded by He et al., https://arxiv.org/abs/1512.03385 (please read the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "- [ResNet components](#ResNet-components)\n",
    "    - [Basic residual block](#Basic-residual-block)\n",
    "    - [Bottleneck block](#Bottleneck-block)\n",
    "- [Full ResNet implementation](#Full-ResNet-implementation)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4213,
     "status": "ok",
     "timestamp": 1609883056520,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDvxa6qhm8nIRx1nbPkyBpdsWMksc1aBZC87nJ=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "t9lthoIcfZT_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic residual block\n",
    "\n",
    "Lets implement a simple (**basic**) **residual block** of two layers of convolution, batch-normalization and ReLU activations (the second ReLU is delayed to after the addition).\n",
    "\n",
    "<img src=\"BasicBlock.png\" width=\"180\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, \n",
    "                     out_planes, \n",
    "                     kernel_size=3, \n",
    "                     stride=stride,\n",
    "                     padding=1, \n",
    "                     bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets quickly test this helper function with 10 input channels, 20 output channels and a stride of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 20, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "l = conv3x3(10, 20,stride=1)\n",
    "print(l(torch.randn(4,10,32,32)).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to create a class that implementes the residual block from the figure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock_v1(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super(BasicBlock_v1, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        3x3 convolution inplanes->outplanes \n",
    "        (spatial size maintained), BN + ReLU\n",
    "        \"\"\" \n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1   = nn.BatchNorm2d(planes)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        \n",
    "        \"\"\"\n",
    "        3x3 convolution inplanes->outplanes \n",
    "        (spatial size maintained) + BN\n",
    "        \"\"\" \n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2   = nn.BatchNorm2d(planes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x \n",
    "    \n",
    "        # conv->bn->relu\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # conv->bn\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # x + F(x) - this realizes the shortcut conn.\n",
    "        print(out.size())\n",
    "        print(residual.size())\n",
    "        out += residual\n",
    "        out = self.relu(out) # final relu (see figure)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the full block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 12, 12])\n",
      "torch.Size([4, 64, 12, 12])\n",
      "torch.Size([4, 64, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "# simple test with batch-size 4, 32 channels, spatial dim. 12x12 \n",
    "x = torch.randn(4,64,12,12)\n",
    "\n",
    "# Push data through a basic block\n",
    "bb = BasicBlock_v1(64,64)\n",
    "print(bb(x).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, but how about strides $>1$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 6, 6])\n",
      "torch.Size([4, 64, 12, 12])\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,64,12,12)\n",
    "try:\n",
    "    bb = BasicBlock_v1(64, 64, stride=2)\n",
    "    out = bb(x)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This happens because the dimensions are not compatible at the $F(x)+x$ operation.  We can easily fix this by a **1x1 convolution** with appropriate striding, i.e., a projection operation on $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes, \n",
    "        out_planes, \n",
    "        kernel_size=1, \n",
    "        stride=stride, \n",
    "        bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock_v2(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock_v2, self).__init__()\n",
    "        \n",
    "        self.conv1      = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1        = nn.BatchNorm2d(planes)\n",
    "        self.relu       = nn.ReLU(inplace=True)\n",
    "        self.conv2      = conv3x3(planes, planes)\n",
    "        self.bn2        = nn.BatchNorm2d(planes)        \n",
    "        self.stride     = stride\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "    \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        \"\"\"\n",
    "        At that point, we check if a downsampling needs to be \n",
    "        applied on x, such that F(x)+x can be computed.\n",
    "        \"\"\"\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If we have multiple input channels, say 32, then the kernel is of size 32x1x1 and this kernel is applied with stride 1 over the full feature map. Mathematically, this corresponds to taking the dot product between the kernel and each feature in the feature map (i.e., again a 32x1x1 tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "# 1x1 convolution from 64 to 64 channels using a stride of 2\n",
    "# This decreases the spatial size by a factor of 2 (obviously)!\n",
    "down_fn = conv1x1(\n",
    "    64,\n",
    "    64,\n",
    "    stride=2)\n",
    "\n",
    "# Input is a tensor of size 4x64x12x12 (so 64 channels)\n",
    "x = torch.randn(4,64,12,12)\n",
    "\n",
    "bb = BasicBlock_v2(\n",
    "    64,\n",
    "    64,\n",
    "    stride=2,\n",
    "    downsample=down_fn)\n",
    "\n",
    "print(bb(x).size()) # Voila!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck block\n",
    "\n",
    "With our previous implementation, we can handle different strides. Next, we look at the **bottleneck** design of a residual block. We can resuse our function that returns a 1x1\n",
    "convolution layer and our function that returns a 3x3 convolution layer.\n",
    "\n",
    "<img src=\"BottleneckBlock.png\" width=\"180\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    The expansion factor controls the number of output \n",
    "    channels of the last 1x1 convolution layer.\n",
    "    \"\"\"\n",
    "    expansion = 4  \n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        self.conv1    = conv1x1(inplanes, planes)\n",
    "        self.bn1      = nn.BatchNorm2d(planes)\n",
    "        self.conv2    = conv3x3(planes, planes, stride)\n",
    "        self.bn2      = nn.BatchNorm2d(planes)\n",
    "        self.conv3    = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3      = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu     = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride   = stride\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "down_fn = conv1x1(256,256,stride=2)\n",
    "x = torch.randn(4,256,12,12)\n",
    "bb = Bottleneck(256,64,stride=2,downsample=down_fn)\n",
    "print(bb(x).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full ResNet implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1609883199877,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDvxa6qhm8nIRx1nbPkyBpdsWMksc1aBZC87nJ=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "9qP-p1XdgDdk"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 821,
     "status": "ok",
     "timestamp": 1609883552313,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDvxa6qhm8nIRx1nbPkyBpdsWMksc1aBZC87nJ=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "Fz_p2bvPfhab",
    "outputId": "12142cde-c8fa-4d22-e9ad-f52d4e3ed094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0      # best test accuracy\n",
    "start_epoch = 0   # start from epoch 0 or last checkpoint epoch\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "6b590e529cfb4dd9af836381394fbd68",
      "c727ca7d3d464cf2a77e252649794f08",
      "598479dca620452a905d6ae1c9eeab21",
      "469b0ba3d5b5409983cc6db37d31946b",
      "3dad0370f823406cb54b818f6f88a7d8",
      "70f8ec1a55644996a131638badbabbd6",
      "66c051e85e5647f99d77583b60f749d8",
      "8ef3f5bffd734eac93c4175861bcc444"
     ]
    },
    "executionInfo": {
     "elapsed": 5851,
     "status": "ok",
     "timestamp": 1609883497418,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDvxa6qhm8nIRx1nbPkyBpdsWMksc1aBZC87nJ=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "k4G8GcorfooT",
    "outputId": "ac3c993d-a60e-41dd-93e7-2a14aa659ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 170498071/170498071 [00:08<00:00, 19572294.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', \n",
    "                                        train=True, \n",
    "                                        download=True, \n",
    "                                        transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                                          batch_size=128, \n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', \n",
    "                                       train=False, \n",
    "                                       download=True, \n",
    "                                       transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, \n",
    "                                         batch_size=100, \n",
    "                                         shuffle=False, \n",
    "                                         num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_small = torch.utils.data.Subset(trainset, torch.tensor([0,500,1000,1001]))\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1609883506907,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDvxa6qhm8nIRx1nbPkyBpdsWMksc1aBZC87nJ=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "tDrbx0juf0V2"
   },
   "outputs": [],
   "source": [
    "classes = ('plane', \n",
    "           'car', \n",
    "           'bird', \n",
    "           'cat', \n",
    "           'deer',\n",
    "           'dog', \n",
    "           'frog', \n",
    "           'horse', \n",
    "           'ship', \n",
    "           'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11284,
     "status": "ok",
     "timestamp": 1609883971043,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDvxa6qhm8nIRx1nbPkyBpdsWMksc1aBZC87nJ=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "mMcYP79Qf5k3"
   },
   "outputs": [],
   "source": [
    "net = ResNet18()\n",
    "net = net.to(device) # move the network to the GPU (if available)\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), \n",
    "                      lr=0.01,\n",
    "                      momentum=0.9, \n",
    "                      weight_decay=5e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 690,
     "status": "ok",
     "timestamp": 1609883978390,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDvxa6qhm8nIRx1nbPkyBpdsWMksc1aBZC87nJ=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "I4ZDZOCjgNJe"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print('{:03d} | {:.5f} | {:.3f}'.format(\n",
    "        epoch,\n",
    "        epoch_loss/len(trainloader),\n",
    "        100.*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1017,
     "status": "ok",
     "timestamp": 1609883979704,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDvxa6qhm8nIRx1nbPkyBpdsWMksc1aBZC87nJ=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "TuGt2sbsh5AK"
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    print('=> Testing acc.: {:.3f}'.format(acc))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "executionInfo": {
     "elapsed": 428621,
     "status": "error",
     "timestamp": 1609884408172,
     "user": {
      "displayName": "Roland Kwitt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDvxa6qhm8nIRx1nbPkyBpdsWMksc1aBZC87nJ=s64",
      "userId": "17953440578497129710"
     },
     "user_tz": -60
    },
    "id": "FHSYr9v5gn8w",
    "outputId": "685c3957-7eaa-403e-8ce6-5ea2067fc916"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, 1+200):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNQYgYngj9GjYcWlfl8J3Cg",
   "collapsed_sections": [],
   "name": "ResNet18-CIFAR10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3dad0370f823406cb54b818f6f88a7d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "469b0ba3d5b5409983cc6db37d31946b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ef3f5bffd734eac93c4175861bcc444",
      "placeholder": "​",
      "style": "IPY_MODEL_66c051e85e5647f99d77583b60f749d8",
      "value": " 170500096/? [00:20&lt;00:00, 94861275.60it/s]"
     }
    },
    "598479dca620452a905d6ae1c9eeab21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70f8ec1a55644996a131638badbabbd6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3dad0370f823406cb54b818f6f88a7d8",
      "value": 1
     }
    },
    "66c051e85e5647f99d77583b60f749d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b590e529cfb4dd9af836381394fbd68": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_598479dca620452a905d6ae1c9eeab21",
       "IPY_MODEL_469b0ba3d5b5409983cc6db37d31946b"
      ],
      "layout": "IPY_MODEL_c727ca7d3d464cf2a77e252649794f08"
     }
    },
    "70f8ec1a55644996a131638badbabbd6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ef3f5bffd734eac93c4175861bcc444": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c727ca7d3d464cf2a77e252649794f08": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
